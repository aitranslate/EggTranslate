/**
 * è½¬å½•æµç¨‹æœåŠ¡
 * å°è£…å®Œæ•´çš„éŸ³è§†é¢‘è½¬å½•æµç¨‹ï¼šè§£ç  -> é™éŸ³æ£€æµ‹ -> åˆ†ç‰‡ -> è½¬å½• -> LLMåˆ†å‰² -> å­—å¹•ç”Ÿæˆ
 */

import { SubtitleEntry, type LLMConfig as BaseLLMConfig } from '@/types';
import type { TranscriptionWord } from '@/types/transcription';
import { DecodedAudio, decodeAudioFile } from './audioDecoder';
import { findSilencePoints, createChunkPlan, type AudioChunk } from '@/utils/silenceDetection';
import { createBatches, logBatchOverview, type BatchInfo } from '@/utils/batchProcessor';
import { formatSRTTime } from '@/utils/timeFormat';
import { getSentenceSegmentationPrompt } from '@/utils/translationPrompts';
import { getLlmWordsAndSplits, mapLlmSplitsToOriginal, reconstructSentences } from '@/utils/sentenceTools';
import { jsonrepair } from 'jsonrepair';
import { callLLM } from '@/utils/llmApi';
import { toast } from 'react-hot-toast';
import { API_CONSTANTS } from '@/constants/api';
import { AUDIO_CONSTANTS, TRANSCRIPTION_BATCH_CONSTANTS, TRANSCRIPTION_PROGRESS } from '@/constants/transcription';
import { toAppError } from '@/utils/errors';

// é‡æ–°å¯¼å‡ºç±»å‹
export type { TranscriptionWord };

/**
 * è½¬å½• LLM é…ç½®ï¼ˆç»§æ‰¿åŸºç¡€ LLM é…ç½®ï¼Œå¢åŠ è½¬å½•ç›¸å…³å­—æ®µï¼‰
 */
export interface TranscriptionLLMConfig extends BaseLLMConfig {
  sourceLanguage: string;
  threadCount?: number;  // LLM å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤ 4
}

/**
 * è½¬å½•æ¨¡å‹æ¥å£
 */
export interface TranscriptionModel {
  transcribe: (
    pcm: Float32Array,
    sampleRate: number,
    options: {
      returnTimestamps: boolean;
      returnConfidences: boolean;
      frameStride: number;
    }
  ) => Promise<{
    words?: TranscriptionWord[];
  }>;
}

/**
 * è¿›åº¦æ›´æ–°å›è°ƒ
 */
export interface ProgressCallbacks {
  onDecoding?: () => void;
  onChunking?: (duration: number) => void;
  onTranscribing?: (current: number, total: number, percent: number) => void;
  onLLMMerging?: () => void;
  onLLMProgress?: (completed: number, total: number, percent: number, tokens: number) => void;
}

/**
 * è½¬å½•ç»“æœ
 */
export interface TranscriptionResult {
  entries: SubtitleEntry[];
  duration: number;
  totalChunks: number;
  tokensUsed: number; // LLM ç»„å¥æ¶ˆè€—çš„ tokens
}

/**
 * è°ƒç”¨ LLM è¿›è¡Œå¥å­åˆ†å‰²
 */
const callLlmApi = async (prompt: string, config: TranscriptionLLMConfig): Promise<{ content: string; tokensUsed: number }> => {
  const result = await callLLM(
    {
      baseURL: config.baseURL,
      apiKey: config.apiKey,
      model: config.model
    },
    [{ role: 'user', content: prompt }],
    { temperature: API_CONSTANTS.DEFAULT_TEMPERATURE }
  );

  return { content: result.content, tokensUsed: result.tokensUsed };
};

/**
 * å¤„ç†å•ä¸ªæ‰¹æ¬¡ï¼ˆLLM å¥å­åˆ†å‰²æˆ–ç›´æ¥è¿æ¥ï¼‰
 */
const processBatch = async (
  batch: BatchInfo,
  llmConfig: TranscriptionLLMConfig
): Promise<{
  sentences: Array<{ sentence: string; startIdx: number; endIdx: number }>;
  tokensUsed: number;
}> => {
  // å¦‚æœæ ‡è®°ä¸ºè·³è¿‡ LLMï¼Œç›´æ¥å°†å•è¯è¿æ¥æˆå¥å­
  if (batch.skipLLM) {
    const originalWords = batch.words.map(w => w.text);
    const sentence = originalWords.join(' ');
    const startIdx = batch.startIdx;
    const endIdx = batch.startIdx + batch.words.length - 1;

    return {
      sentences: [{
        sentence,
        startIdx,
        endIdx
      }],
      tokensUsed: 0
    };
  }

  // è°ƒç”¨ LLM è¿›è¡Œå¥å­åˆ†å‰²
  const wordsList = batch.words.map(w => w.text);
  const segmentationPrompt = getSentenceSegmentationPrompt(
    wordsList,
    TRANSCRIPTION_BATCH_CONSTANTS.LLM_MAX_WORDS,
    llmConfig.sourceLanguage
  );

  const { content: llmResponse, tokensUsed } = await callLlmApi(segmentationPrompt, llmConfig);

  // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½• LLM åŸå§‹å“åº”
  console.log(`[TranscriptionPipeline] Batch ${batchIdx + 1} LLM response:`, {
    responseLength: llmResponse.length,
    responsePreview: llmResponse.substring(0, 500),
    isEmpty: !llmResponse,
    startsWithBrace: llmResponse.trim().startsWith('{'),
    startsWithCodeBlock: llmResponse.trim().startsWith('```')
  });

  // ä½¿ç”¨ jsonrepair æ¸…ç† markdown ä»£ç å—ç­‰æ ¼å¼é—®é¢˜
  const repairedJson = jsonrepair(llmResponse);

  // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•ä¿®å¤åçš„ JSON
  console.log(`[TranscriptionPipeline] Batch ${batchIdx + 1} Repaired JSON:`, {
    repairedLength: repairedJson.length,
    repairedPreview: repairedJson.substring(0, 500),
    isEmpty: !repairedJson,
    isValidJson: (() => {
      try {
        JSON.parse(repairedJson);
        return true;
      } catch {
        return false;
      }
    })()
  });

  const parsed = JSON.parse(repairedJson);
  const llmSentences = parsed.sentences || [];

  // æ ¸å¿ƒé€»è¾‘ï¼šç”¨åºåˆ—åŒ¹é…å°† LLM åˆ†ç»„æ˜ å°„å›åŸå§‹å•è¯
  const originalCleanWords = batch.words.map(w => w.text.toLowerCase().replace(/[^a-z0-9]/g, ''));

  // æå– LLM çš„æ¸…ç†åå•è¯å’Œåˆ†å‰²ç‚¹
  const [llmCleanWords, llmSplitIndices] = getLlmWordsAndSplits(llmSentences);

  // ç”¨åºåˆ—åŒ¹é…å°†åˆ†å‰²ç‚¹æ˜ å°„å›åŸå§‹å•è¯
  const originalSplitIndices = mapLlmSplitsToOriginal(originalCleanWords, llmCleanWords, llmSplitIndices);

  // ç”¨åŸå§‹å•è¯é‡å»ºå¥å­ï¼ˆä¿ç•™åŸå§‹æ–‡æœ¬ï¼ŒåŒ…æ‹¬å¤§å°å†™å’Œæ ‡ç‚¹ï¼‰
  const originalWords = batch.words.map(w => w.text);
  const reconstructedSentences = reconstructSentences(originalWords, originalSplitIndices);

  // ç›´æ¥ä½¿ç”¨ originalSplitIndices è®¡ç®—æ¯ä¸ªå¥å­çš„ç´¢å¼•èŒƒå›´
  const completeSplitIndices = [...originalSplitIndices];
  if (completeSplitIndices.length === 0 || completeSplitIndices[completeSplitIndices.length - 1] !== originalWords.length) {
    completeSplitIndices.push(originalWords.length);
  }

  const sentenceMappings: Array<{ sentence: string; startIdx: number; endIdx: number }> = [];
  let lastSplitIdx = 0;
  for (let i = 0; i < completeSplitIndices.length; i++) {
    const splitIdx = completeSplitIndices[i];
    if (splitIdx > lastSplitIdx) {
      const startIdx = batch.startIdx + lastSplitIdx;
      const endIdx = batch.startIdx + splitIdx - 1;
      sentenceMappings.push({
        sentence: reconstructedSentences[i] || originalWords.slice(lastSplitIdx, splitIdx).join(' '),
        startIdx,
        endIdx
      });
    }
    lastSplitIdx = splitIdx;
  }

  return {
    sentences: sentenceMappings,
    tokensUsed
  };
};

/**
 * æ‰§è¡Œè½¬å½•æµç¨‹
 * @param fileRef - éŸ³è§†é¢‘æ–‡ä»¶å¼•ç”¨
 * @param model - è½¬å½•æ¨¡å‹
 * @param llmConfig - LLM é…ç½®
 * @param callbacks - è¿›åº¦å›è°ƒ
 * @returns è½¬å½•ç»“æœ
 */
export const runTranscriptionPipeline = async (
  fileRef: File,
  model: TranscriptionModel,
  llmConfig: TranscriptionLLMConfig,
  callbacks: ProgressCallbacks = {}
): Promise<TranscriptionResult> => {
  // 1. è§£ç éŸ³é¢‘
  callbacks.onDecoding?.();
  const { pcm, duration } = await decodeAudioFile(fileRef, AUDIO_CONSTANTS.SAMPLE_RATE);

  // 2. é™éŸ³æ£€æµ‹å’Œåˆ†ç‰‡
  callbacks.onChunking?.(duration);
  const silencePoints = findSilencePoints(pcm, AUDIO_CONSTANTS.SAMPLE_RATE);
  console.log('[Transcription] æ£€æµ‹åˆ°', silencePoints.length, 'ä¸ªé™éŸ³ç‚¹');

  const chunks = createChunkPlan(pcm, AUDIO_CONSTANTS.SAMPLE_RATE, silencePoints);
  const totalChunks = chunks.length;
  console.log('[Transcription] åˆ†ç‰‡è®¡åˆ’:', chunks.map(c => `${Math.floor(c.duration)}s`).join(', '));

  await new Promise(r => setTimeout(r, API_CONSTANTS.STATE_UPDATE_DELAY_MS));
  toast(`éŸ³é¢‘æ—¶é•¿: ${Math.floor(duration / 60)}:${(Math.floor(duration % 60)).toString().padStart(2, '0')}ï¼ŒåŸºäºé™éŸ³æ£€æµ‹åˆ‡åˆ†æˆ ${totalChunks} ä¸ªç‰‡æ®µ`);

  // 3. æ¨¡å‹è½¬å½•
  const allWords: TranscriptionWord[] = [];

  if (totalChunks === 1) {
    // çŸ­éŸ³é¢‘ï¼Œç›´æ¥å¤„ç†
    callbacks.onTranscribing?.(1, 1, TRANSCRIPTION_PROGRESS.SHORT_AUDIO_PROGRESS);
    const res = await model.transcribe(pcm, AUDIO_CONSTANTS.SAMPLE_RATE, {
      returnTimestamps: true,
      returnConfidences: true,
      frameStride: AUDIO_CONSTANTS.FRAME_STRIDE
    });

    if (res.words) {
      allWords.push(...res.words);
    }
  } else {
    // é•¿éŸ³é¢‘ï¼ŒæŒ‰åˆ†ç‰‡å¤„ç†
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const chunkPcm = pcm.slice(chunk.start, chunk.end);
      const timeOffset = chunk.start / AUDIO_CONSTANTS.SAMPLE_RATE;

      callbacks.onTranscribing?.(
        i + 1,
        chunks.length,
        Math.floor(TRANSCRIPTION_PROGRESS.LONG_AUDIO_PROGRESS_START + (i / chunks.length) * TRANSCRIPTION_PROGRESS.LONG_AUDIO_PROGRESS_RANGE)
      );

      const chunkRes = await model.transcribe(chunkPcm, AUDIO_CONSTANTS.SAMPLE_RATE, {
        returnTimestamps: true,
        returnConfidences: true,
        frameStride: AUDIO_CONSTANTS.FRAME_STRIDE
      });

      // è°ƒæ•´æ—¶é—´åç§»
      if (chunkRes.words) {
        chunkRes.words.forEach(w => {
          w.start_time += timeOffset;
          w.end_time += timeOffset;
        });
        allWords.push(...chunkRes.words);
      }
    }
  }

  // 4. LLM å¥å­åˆ†å‰²
  callbacks.onLLMMerging?.();

  // æ‰¹æ¬¡åˆ‡åˆ†
  const batches = createBatches(allWords);
  logBatchOverview(batches);

  // æŒ‰çº¿ç¨‹æ•°åˆ†ç»„å¤„ç†æ‰¹æ¬¡ï¼ˆä¸ç¿»è¯‘æµç¨‹ä¿æŒä¸€è‡´ï¼‰
  const threadCount = llmConfig.threadCount || 4;
  const allReconstructedSentences: Array<Array<{ sentence: string; startIdx: number; endIdx: number }>> = [];
  let completedBatches = 0;
  let totalTokensUsed = 0;

  for (let i = 0; i < batches.length; i += threadCount) {
    const currentBatchGroup = batches.slice(i, i + threadCount);

    const batchPromises = currentBatchGroup.map(async (batch) => {
      const batchIdx = batches.indexOf(batch);
      try {
        const { sentences, tokensUsed } = await processBatch(batch, llmConfig);
        allReconstructedSentences[batchIdx] = sentences;
        totalTokensUsed += tokensUsed;

        // æ›´æ–°è¿›åº¦
        completedBatches++;
        callbacks.onLLMProgress?.(
          completedBatches,
          batches.length,
          Math.floor(TRANSCRIPTION_PROGRESS.LLM_PROGRESS_START + (completedBatches / batches.length) * TRANSCRIPTION_PROGRESS.LLM_PROGRESS_RANGE),
          totalTokensUsed
        );
      } catch (error) {
        const reasonText = batch.reason === 'pause'
          ? `pause ${batch.pauseGap?.toFixed(1)}s`
          : batch.reason === 'punctuation' ? 'punctuation' : 'limit';
        const appError = toAppError(error);
        console.error(`[TranscriptionPipeline] Batch ${batchIdx + 1} (${batch.words.length} words, ${reasonText}) å¤„ç†å¤±è´¥:`, appError.message);
        // æŠ›å‡ºé”™è¯¯ï¼Œåœæ­¢è½¬å½•æµç¨‹
        throw new Error(`LLM å¥å­åˆ†å‰²å¤±è´¥ï¼ˆæ‰¹æ¬¡ ${batchIdx + 1}ï¼‰: ${appError.message}`);
      }
    });

    await Promise.all(batchPromises);
  }

  // 5. ç”Ÿæˆå­—å¹•æ¡ç›®
  const entries: SubtitleEntry[] = [];
  let entryId = 1;

  for (const batchSentences of allReconstructedSentences) {
    for (const { sentence, startIdx, endIdx } of batchSentences) {
      if (startIdx >= allWords.length || endIdx >= allWords.length) {
        continue;
      }

      entries.push({
        id: entryId++,
        startTime: formatSRTTime(allWords[startIdx].start_time),
        endTime: formatSRTTime(allWords[endIdx].end_time),
        text: sentence,
        translatedText: ''
      });
    }
  }

  if (entries.length === 0) {
    throw new Error('LLM å¥å­åˆ†å‰²å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API é…ç½®');
  }

  return {
    entries,
    duration,
    totalChunks,
    tokensUsed: totalTokensUsed
  };
};
