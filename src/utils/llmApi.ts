import { RateLimiter, rateLimiter } from './rateLimiter';
import { API_CONSTANTS } from '@/constants/api';

// å¯¼å…¥ç±»å‹å¹¶é‡æ–°å¯¼å‡ºï¼Œä¿æŒå‘åå…¼å®¹
import type { LLMConfig } from '@/types';
export type { LLMConfig };

interface LLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface CallLLMOptions {
  maxRetries?: number;
  temperature?: number;
  signal?: AbortSignal;
}

interface CallLLMResult {
  content: string;
  tokensUsed: number;
}

// æ¨¡å—çº§çš„ API Key è½®è¯¢ç´¢å¼•ï¼ˆé¿å…ä¾èµ– React çš„ useRefï¼‰
let apiKeyIndex = 0;

/**
 * ä»å¤šä¸ª API Key ä¸­è½®è¯¢è·å–ä¸€ä¸ª
 */
function getNextApiKey(apiKeyStr: string): string {
  const apiKeys = apiKeyStr.split('|').map(key => key.trim()).filter(key => key.length > 0);
  if (apiKeys.length === 0) {
    throw new Error('æœªé…ç½®æœ‰æ•ˆçš„APIå¯†é’¥');
  }

  const currentIndex = apiKeyIndex % apiKeys.length;
  apiKeyIndex = (apiKeyIndex + 1) % apiKeys.length;

  return apiKeys[currentIndex];
}

/**
 * é‡ç½® API Key è½®è¯¢ç´¢å¼•ï¼ˆç”¨äºæµ‹è¯•æˆ–é‡ç½®çŠ¶æ€ï¼‰
 */
export function resetApiKeyIndex(): void {
  apiKeyIndex = 0;
}

/**
 * ç»Ÿä¸€çš„ LLM API è°ƒç”¨å‡½æ•°
 *
 * è‡ªåŠ¨å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
 * 1. å¤±è´¥é‡è¯•ï¼ˆæœ€å¤š MAX_RETRIES æ¬¡ï¼ŒæŒ‡æ•°é€€é¿ï¼‰
 * 2. å¤š API Key è½®è¯¢ï¼ˆæ”¯æŒç”¨ | åˆ†éš”å¤šä¸ª keyï¼‰
 * 3. é¢‘ç‡é™åˆ¶ï¼ˆé€šè¿‡ RPM é…ç½®ï¼‰
 * 4. Token ç»Ÿè®¡ï¼ˆè‡ªåŠ¨è¿”å›æ¶ˆè€—çš„ tokensï¼‰
 *
 * @param config LLM é…ç½®
 * @param messages æ¶ˆæ¯æ•°ç»„
 * @param options é€‰é¡¹
 * @returns LLM å“åº”å†…å®¹å’Œ Token æ¶ˆè€—
 */
export async function callLLM(
  config: LLMConfig,
  messages: LLMMessage[],
  options: CallLLMOptions = {}
): Promise<CallLLMResult> {
  const { maxRetries = API_CONSTANTS.MAX_RETRIES, temperature = API_CONSTANTS.DEFAULT_TEMPERATURE, signal } = options;

  // è®¾ç½®é¢‘ç‡é™åˆ¶
  if (config.rpm !== undefined) {
    rateLimiter.setRPM(config.rpm);
  }

  let lastError: unknown = null;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    if (signal?.aborted) {
      throw new Error('è¯·æ±‚è¢«å–æ¶ˆ');
    }

    try {
      // é¢‘ç‡é™åˆ¶ï¼šç­‰å¾…å¯ç”¨
      await rateLimiter.waitForAvailability();

      if (signal?.aborted) {
        throw new Error('è¯·æ±‚è¢«å–æ¶ˆ');
      }

      // å¤š key è½®è¯¢ï¼šè·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API key
      const apiKey = getNextApiKey(config.apiKey);

      const response = await fetch(`${config.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model: config.model,
          messages: messages,
          temperature,
          max_tokens: 2048
        }),
        signal
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: { message: response.statusText } }));
        throw new Error(errorData.error?.message || `HTTP ${response.status}`);
      }

      const data = await response.json();

      // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½• API åŸå§‹å“åº”
      console.log('[LLM API] Raw response:', {
        hasChoices: !!data.choices,
        choicesLength: data.choices?.length,
        firstChoice: data.choices?.[0],
        usage: data.usage
      });

      const content = data.choices[0]?.message?.content || '';

      // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æå–çš„å†…å®¹
      if (!content) {
        console.error('[LLM API] âš ï¸ Empty content detected!', {
          fullResponse: data,
          choices: data.choices,
          hasMessage: !!data.choices?.[0]?.message
        });
      } else {
        console.log('[LLM API] âœ… Content extracted:', {
          length: content.length,
          preview: content.substring(0, 200),
          isJson: content.trim().startsWith('{')
        });
      }

      // è®¡ç®— token æ¶ˆè€—ï¼ˆç²—ç•¥ä¼°è®¡ï¼Œå®é™…åº”è¯¥ä½¿ç”¨ usage.total_tokensï¼‰
      const tokensUsed = data.usage?.total_tokens || 0;

      return { content, tokensUsed };
    } catch (error) {
      lastError = error;

      // å¦‚æœæ˜¯å–æ¶ˆé”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
      if (error instanceof Error && error.name === 'AbortError') {
        throw error;
      }

      // æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯
      if (attempt === maxRetries) {
        throw error;
      }

      // æŒ‡æ•°é€€é¿
      const delay = Math.min(1000 * Math.pow(2, attempt - 1), API_CONSTANTS.RETRY_DELAY_MS);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }

  throw lastError;
}
